# Minimal Teacher-Education Kit (Flux-aligned AI literacy)

This kit is the smallest repeatable way to teach **context partnering** using this repo’s artifacts.
It is framework-delivery-through-tools: scenarios + row packs + single-column rubrics.

## Who this is for
Teacher educators, coaches, PD facilitators, and department leads.

## What participants should leave with
- A shared definition of **context partnering** (and what it is not).
- A usable row set (content rows + 2–4 AI literacy core rows) for one assignment.
- A calibrated sense of what counts as evidence for **Ownership** and **Verification**.
- A plan to run one more practice cycle in their own context.

## The minimum artifacts you need (from this repo)
- `CONCEPTS/context-partnering.md`
- `RUBRIC/student-single-column-rubric.md`
- `ROW_PACKS/ai-literacy-core.md`
- One scenario from `SCENARIOS/` (start with elementary define-a-line, or swap your own)

(Optional facilitator overlay)
- `RUBRIC/teacher-single-column-rubric.md`
- `ALIGNMENT.md`

---

## 60–90 minute facilitation loop (the kit)

### 0) Set the frame (5–10 min)
Say in plain language:
- “AI is optional. The goal is not better prompts; it’s better **ownership + verification** while building shared context.”
- “Student rubric is primary evidence. Teacher overlay is optional.”

### 1) Run a shared scenario (10–15 min)
- Everyone reads the same scenario.
- Everyone drafts a quick first-pass solution/response (no perfection).

### 2) Choose a row set (5 min)
- Pick **2 content rows** from the scenario/assignment.
- Add **2 AI literacy rows** from `ROW_PACKS/ai-literacy-core.md` (recommended starters):
  - Ownership row (goal + choices)
  - Verification row (treat output as candidate + check)

### 3) Use the student rubric as a mirror (10–15 min)
- Each participant places themselves: one column per row + brief evidence.
- Pair-share: “one strong move” and “one missing move” in the work.

### 4) Calibration round (15–20 min)
- In small groups, compare evidence for the same row:
  - What would count as “Understanding” for this row in your context?
  - What common misconception might show up?
- Write a 1–2 bullet **Understanding anchor** per chosen row (teacher scaffold).

### 5) Re-entry cues (10–15 min)
- Everyone revises once, targeting the missing move (optional but recommended).
- Name the re-entry cue in plain language:
  - “What check would make this trustworthy?”
  - “What definition would make it workable?”
  - “What question would sharpen the context?”

### 6) Commit to the next cycle (5 min)
Each participant writes:
- “Next time, I will run this with ___ scenario / assignment.”
- “I will include these 2–4 rows.”
- “I will look for this evidence: ___.”

---

## Common drifts → re-entry cues (starter set)
Use these as facilitator prompts, not as “levels.”

- **If you see outsourcing authority** (“AI said, so it’s true”) →
  **Re-entry cue:** What evidence would make this claim yours?
- **If you see vague prompting** (“tell me about…”) →
  **Re-entry cue:** What would make the question more specific or checkable?
- **If you see premature collapse** (“I don’t know”) →
  **Re-entry cue:** What is still unclear, and what is the smallest next step?
- **If you see hidden tool use / integrity issues** →
  **Re-entry cue:** What needs to be disclosed or bounded for this to stay safe and honest?

---

## Questions to carry (not prompts to recite)
These are questions a teacher educator can *hold internally* while watching work and listening.
They guide noticing, calibration, and re-entry without turning facilitation into a script.
Use whatever fits your context; silence is allowed.

### Ownership (agency / authorship)
- Where did the locus of authority move?
- What choice did the learner make, and what reason did they give?
- What would it look like for the learner to reclaim authorship here?

### Verification (validate with evidence)
- Which claim is “load-bearing” in this work?
- What is one domain-appropriate check that would increase confidence?
- If this were wrong, how would we find out quickly?

### Context building (make the frame workable)
- What assumption is silently doing the work?
- What definition would make this task workable right now?
- What boundary case would clarify the concept?

### Staying with the unknown
- What is unclear *specifically*, and is it being named?
- What’s the smallest next step that keeps learning alive?
- Where is the impulse to collapse, and what would “stay with it” look like?

### Integrity & boundaries (safe / honest / appropriate)
- What disclosure is needed for honesty/learning?
- Where are privacy/consent/class norms relevant?
- When is “don’t use AI” the most skillful move?
