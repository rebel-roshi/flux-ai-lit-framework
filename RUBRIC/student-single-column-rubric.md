# Student Single Column Rubric Template (with teacher-scaffolded “Understanding” column)

## How it works
- Each row is a learning target.
- The teacher provides the **Understanding** column (what “meets” looks like).
- For each row, the student chooses **one column** that best matches their current state and writes brief evidence there.

---

## Row template (copy/paste per learning target)

### Learning Target: ________________________________________

| Not curious | Struggling | Understanding (teacher scaffold) | Excelling |
|---|---|---|---|
| ☐ **If this is me right now, my evidence:**<br><br>**Evidence I can show (examples):**<br>- A picture / diagram / graph I made<br>- A worked example (my steps)<br>- An example + a non-example (and why)<br>- A sentence explaining *why* (my reasoning)<br>- A check I used (estimate, try another method, test a point, counterexample, etc.)<br>- A correction I made after checking<br><br>**Question / next step (optional, 1 line):**<br>-  | ☐ **If this is me right now, my evidence:**<br><br>**Evidence I can show (examples):**<br>- What I tried so far (even if incomplete)<br>- Where I got stuck (be specific)<br>- One example I can do + one I can’t yet<br>- A mistake I found (and what I think caused it)<br>- A check I tried (and what it showed me)<br><br>**Question / next step (optional, 1 line):**<br>-  | ☐ **If this is me right now, my evidence:**<br><br>**Meets looks like (teacher definition):**<br>- <br><br>**My evidence (pick 1–3):**<br>- A picture / diagram / graph I made<br>- A worked example (my steps)<br>- An example + a non-example (and why)<br>- A sentence explaining *why* (my reasoning)<br>- A check I used (estimate, try another method, test a point, counterexample, etc.)<br>- A correction I made after checking<br><br>**Question / next step (optional, 1 line):**<br>-  | ☐ **If this is me right now, my evidence:**<br><br>**Evidence I can show (examples):**<br>- I can solve a harder / new kind of problem using this idea<br>- I can explain it clearly to someone else (with an example)<br>- I can connect it to another idea we learned<br>- I can find an edge case or limitation and handle it<br>- I can verify my work in two different ways<br><br>**Question / next step (optional, 1 line):**<br>-  |

---

## Evidence menu (teacher-facing or student-facing, optional to include)
Use this as a bank. Students don’t need to use all of it—just enough to show the claim is real.

### Types of evidence (general)
- **Artifact:** drawing, diagram, graph, table, model, annotated picture
- **Process:** steps, intermediate work, labeled reasoning, “what I tried”
- **Comparison:** two methods, two representations, “same answer two ways”
- **Verification:** estimate, substitution, test point, units check, boundary/edge case, counterexample
- **Explanation:** “because…” statement, definition in own words, justification
- **Revision:** what changed after feedback/checking and why

### What “good evidence” sounds like
- “I tested my rule with a new example and it still worked.”
- “Here’s a non-example and why it fails the definition.”
- “I checked by substituting the point into the equation.”
- “I found my mistake: I mixed up ___ and ___. I corrected it by ___.”

### “Stuck” evidence (still valuable)
- “I can do this part, but I get stuck when ___.”
- “I tried ___ and got ___; I think the issue is ___.”
- “My drawing doesn’t match my equation; I don’t know why yet.”

---

## Column label tweak (optional)
These columns can be anything you want and can include more columns. For example: if “Not curious” feels too loaded for your classroom culture, you can swap it with something like:

“Not engaging yet” / “Not attempted yet” / “Not invested yet”

---

# Where “AI used” or "AI literacy assessment" goes

Two solid patterns:

## Pattern A — “AI used” becomes its own row (only when the task explicitly involves AI)
Add a row like:

**Learning Target:** I used AI as a context partner responsibly (**evidence:** what I asked + what I checked/changed).

This makes sense for AI-integrated assignments.

## Pattern B — Keep AI out of the student rubric, and assess it in the teacher rubric
This is often cleaner: students focus on content, and the teacher uses an AI-literacy/Flux overlay to evaluate the student’s self-assessment artifact (evidence quality, checking, ownership, etc.).
