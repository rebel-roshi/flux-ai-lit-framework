## Why this works (and why we use this rubric shape)

This rubric is designed to shift the classroom from “teacher as judge” to “students as sense-makers”
*without* losing rigor.

### The five core practices (what becomes observable)
- **Ownership (agency / authorship):** Who is responsible for meaning in the work, and how that ownership shows up in choices and explanations. See [Core practices](../LENSES/core-practice-cards.md#ownership-agency--authorship).
- **Verification (validate with evidence):** Whether claims are treated as candidates and checked with domain evidence. See [Core practices](../LENSES/core-practice-cards.md#verification-validate-with-evidence).
- **Context building (make the frame workable):** Whether the frame is made workable (terms, assumptions, constraints) before trust or use. See [Core practices](../LENSES/core-practice-cards.md#context-building-make-the-frame-workable).
- **Staying with the unknown:** Whether uncertainty is named and used productively toward a next step. See [Core practices](../LENSES/core-practice-cards.md#staying-with-the-unknown).
- **Integrity & boundaries (safe / honest / appropriate):** Whether the work stays honest, safe, and appropriate to policy and purpose. See [Core practices](../LENSES/core-practice-cards.md#integrity--boundaries-safe--honest--appropriate).

### 1) It inverts control while keeping a shared standard
- The teacher scaffolds the **Understanding** column (what “meets” looks like), so the target is clear.
- Students choose **one column per row** and provide evidence, so they practice ownership of where they are.

### 2) It supports productive struggle
Students can choose “Struggling” and still succeed at the task of learning because their job is to:
- show what they tried,
- name what’s unclear,
- identify a next step.
That turns “stuck” into information the teacher can act on while circulating.

### 3) It makes metacognition concrete (not extra)
Instead of a separate reflection assignment, the rubric asks students to:
- make a claim about their current understanding,
- attach evidence,
- name a question/next step.
This is the metacognitive loop in a lightweight form.

### 4) It keeps AI use (when present) inside verification and ownership
If AI is involved, the expectation is not “use AI,” but:
- treat AI output as a *candidate*,
- verify with your own work (examples, counterexamples, checks),
- record what changed (or why nothing needed to change).
This is AI literacy as *practice*, not as tool fluency.

---

## Making the student rubric “matter” (assessment/grades)

This framework intentionally does **not** require a single grading method. Different contexts (age, subject, policy)
will use different approaches. The key requirement is:

> The student’s rubric entry must be treated as a meaningful artifact, not overwritten by teacher judgment without a learning step.

Below are compatible “grading handshakes” you can choose from:

### Option A: Student-first with teacher audit (conference-based)
- Student self-assesses (one box per row + evidence).
- Teacher confirms or asks a verification question (“show me a non-example,” “where’s the check?”).
- Student revises evidence and/or self-assessment.
- The student’s post-conference rubric drives the record/grade.

### Option B: Two-part outcome (content + self-assessment quality)
- Content level comes from the student rubric (after any quick checks).
- A small separate score evaluates the *quality of evidence and checking* in the rubric artifact
  (not “how harshly” the student rated themselves).

### Option C: Calibration (student + teacher + peer)
- Student self-assesses.
- Peer/teacher assesses using the same Understanding scaffold.
- Differences become feedback; the goal is improving judgment and verification.

### Option D: Formative-only (no points, high learning value)
- Use the rubric for reflection and feedback cycles.
- Teacher uses it to decide next instruction while circulating.
