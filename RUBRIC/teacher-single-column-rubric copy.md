# Teacher Overlay Rubric (Context Partnering / AI Literacy)

## What this is
This rubric assesses **context partnering / AI literacy** as demonstrated through a student’s work artifact
(which may or may not include AI). It is designed to be **portable across domains** by swapping the domain evidence, but is focused on
AI literacy for purposes of the flux framework.

The teacher provides the **Understanding** column (what “meets” looks like).
For each row, the teacher selects **one column** and writes brief evidence.

> If your classroom uses different labels, rename columns freely.

---

## How to use (agnostic)
- Use with student work, student rubrics, conferences, or observations.
- AI use is **not required**. When AI is present, it becomes part of the evidence trail.

---

## Row template (copy/paste per dimension)

### Dimension: ________________________________________

| Not evident | Developing | Understanding (teacher scaffold) | Extending |
|---|---|---|---|
|  |  | ☐ **If this fits, teacher evidence/notes:**<br><br>**Meets looks like (teacher definition):**<br>- <br>- <br><br>**Evidence I saw (brief):**<br>- <br><br>**One question / next step (optional):**<br>-  |  |

---

## Core dimensions (AI literacy / context partnering)
(Keep these stable; swap the domain evidence underneath.)

### 1) Ownership (who is responsible for meaning?)
**Meets looks like (teacher):**
- Student makes and justifies choices (“I decided… because…”).
- Student does not outsource authority to AI/tool/teacher.
- Student can explain what they did vs what a tool suggested.

### 2) Verification / self-checking (is output treated as a candidate?)
**Meets looks like (teacher):**
- Student uses appropriate checks for the domain (examples, tests, sources, counterexamples, etc.).
- Student records at least one check or stress test when needed.
- If AI is used, student verifies rather than copies.

### 3) Context building (is the frame made workable?)
**Meets looks like (teacher):**
- Student clarifies key terms/assumptions/purpose enough to proceed.
- Student can distinguish close concepts (example/non-example, boundary cases).
- Student updates their approach as the context evolves.

### 4) UNKNWN handling (is uncertainty used productively?)
**Meets looks like (teacher):**
- Student can name what is unclear or unverified.
- Student takes a next step (question, test, partial attempt, seek feedback).
- Student tolerates ambiguity long enough to learn (doesn’t collapse early).

### 5) Integrity & boundaries (safety, attribution, appropriateness)
**Meets looks like (teacher):**
- Student follows classroom norms for AI/tool use (attribution if required, no sensitive data).
- Student uses tools appropriately for the task.
- Student maintains academic integrity in a way consistent with the class policy.

---

## Domain evidence swap (examples)
Use these as evidence types; you don’t need separate rubrics for each domain.

### Math
- checks: test a point, compare representations, estimate, counterexample, edge case (vertical line)
- evidence: annotated work, graphs, tables, explanations

### Writing / ELA
- checks: quote accuracy, revision trail, source validation, style consistency, argument structure
- evidence: drafts with changes, citation notes, reasoning about edits

### Science
- checks: control variables, unit analysis, plausibility, replicate reasoning, source quality
- evidence: lab notes, data tables, model sketches, claims-evidence-reasoning

### History / Social studies
- checks: source credibility, corroboration, bias analysis, context of claims
- evidence: sourcing notes, comparison of accounts, argument outline

---

## Optional note on AI use
AI can be present or not. When it is present, “Meets” includes:
- what was asked,
- what was verified,
- what changed (or why nothing changed).
